# Meow 对话链路全流程说明

本文档描述当前代码实现下，从用户输入到前端 TTS 播放的完整链路，并标注关键代码入口。

## 1. 范围与目标

覆盖两条主链路：

1. 文本输入：`text` -> `LLM` -> `TTS` -> 前端播放
2. 语音输入：`audio` -> `ASR` -> `LLM` -> `TTS` -> 前端播放

核心目标：

1. 解释每一层职责与数据格式
2. 说明并发、顺序保障、中断机制
3. 给出可直接跳转的关键代码位置

## 2. 总体组件关系

### 2.1 前端（Vue）

1. WebSocket 连接与消息收发：`meow-client/src/stores/websocket.js:13`
2. 聊天页面与输入逻辑：`meow-client/src/views/ChatView.vue:126`
3. Opus 解码与播放：`meow-client/src/utils/opusPlayer.js:119`

### 2.2 后端（Spring WebSocket）

1. WebSocket 路由入口：`meow-server/src/main/java/com/miaomiao/assistant/websocket/ConversationWebSocketHandler.java:47`
2. 消息分发中心：`meow-server/src/main/java/com/miaomiao/assistant/websocket/handler/MessageHandlerRegistry.java:59`
3. 会话编排入口：`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/ConversationService.java:35`
4. 子服务：
   `ASRService` `LLMService` `TTSService`
5. 统一消息下行发送：`meow-server/src/main/java/com/miaomiao/assistant/websocket/session/WebSocketMessageSender.java:64`

## 3. 协议与数据格式

### 3.1 WebSocket 消息类型

服务端通过 `WSMessage` 多态反序列化：
`meow-server/src/main/java/com/miaomiao/assistant/websocket/message/WSMessage.java:17`

客户端 -> 服务端：

1. `text`（文本输入）
2. `audio`（音频输入）

服务端 -> 客户端：

1. `stt`（ASR 文本）
2. `llm_token`（打字效果 token 流）
3. `tts`（音频帧）

### 3.2 音频帧格式（服务端 TTS 下行）

服务端发送的每条 `tts` 消息里，`data` 字段是 Base64，解码后是：

```text
[2字节小端长度][Opus帧数据]
```

一段句子的所有 Opus 帧会被逐帧发送，每帧一条 `tts` 消息。

关键位置：

1. Opus 编码打包：`meow-server/src/main/java/com/miaomiao/assistant/codec/OpusCodec.java:48`
2. 按帧切分并发送：`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/pipeline/ConcurrentTTSProcessor.java:304`
3. 最后一帧标记 `finished=true`：`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/pipeline/ConcurrentTTSProcessor.java:332`

## 4. 链路 A：文本输入 -> TTS 播放

### 4.1 前端发送文本

1. 用户点击发送或回车
2. `ChatView.sendText()` 组装 `{type:'text', text:...}`：
   `meow-client/src/views/ChatView.vue:193`
3. `websocketStore.send()` 自动补 `timestamp` 并发出：
   `meow-client/src/stores/websocket.js:62`

### 4.2 后端接收与分发

1. `ConversationWebSocketHandler.handleTextMessage()` 反序列化 `WSMessage`：
   `meow-server/src/main/java/com/miaomiao/assistant/websocket/ConversationWebSocketHandler.java:47`
2. `MessageHandlerRegistry.dispatch()` 按 `type` 路由：
   `meow-server/src/main/java/com/miaomiao/assistant/websocket/handler/MessageHandlerRegistry.java:59`
3. `TextMessageHandler.handle()` 调用会话编排入口：
   `meow-server/src/main/java/com/miaomiao/assistant/websocket/handler/TextMessageHandler.java:33`

### 4.3 会话编排（LLM + TTS）

`ConversationService.processTextInput()`：
`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/ConversationService.java:84`

处理顺序：

1. 清理中断态：`SessionState.resetAborted()`
2. 记录性能起点：`recordUserInputStart()`
3. 调用 `LLMService.processLLMStream()` 获取 token 流
4. 将 token 流交给 `TTSService.processTTSStream()`

### 4.4 LLM 流

`LLMService.processLLMStream()`：
`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/LLMService.java:47`

关键动作：

1. 组装上下文消息：
   系统提示词 + 历史 + 当前用户输入
2. 调 `llmManager.chatStream(...)` 获取模型增量
3. 每个 token：
   发送 `llm_token` 到前端（打字效果）
   并 `tokenSink.tryEmitNext(content)` 推给 TTS 管道
4. 结束时：
   发送 `llm_token(finished=true)`，
   然后写入会话历史（user + assistant）

关键位置：

1. token 发送：`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/LLMService.java:115`
2. token 进入 TTS：`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/LLMService.java:121`
3. 会话历史更新：`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/LLMService.java:136`

### 4.5 TTS 流

`TTSService.processTTSStream()`：
`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/TTSService.java:62`

实际使用 `ConcurrentTTSFrameProcessor`：

1. 每次 token 到来，封装 `Frames.TextFrame`
2. 结束时发送 `Frames.EndFrame`
3. 内部执行文本聚合、预处理、并发 TTS、顺序发送

## 5. 链路 B：语音输入 -> TTS 播放

### 5.1 前端采集与发送

1. `startRecording()` 使用 `MediaRecorder` 录音：
   `meow-client/src/views/ChatView.vue:214`
2. `ondataavailable` 中转成 base64，发送：
   `{type:'audio', format:'webm', data, isLast:true}`

当前页面实现是一次录音一次发送（`isLast=true`）。

### 5.2 后端语音入口

1. `AudioMessageHandler.handle()` 先累积音频：
   `meow-server/src/main/java/com/miaomiao/assistant/websocket/handler/AudioMessageHandler.java:33`
2. `isLast=true` 时取出整段数据：
   `state.getAndClearAudioBuffer()`
3. 调 `ConversationService.processAudioInput()`：
   `meow-server/src/main/java/com/miaomiao/assistant/websocket/service/ConversationService.java:35`

### 5.3 ASR -> 文本

1. `ASRService.speechToText()` 构造 `ASROptions`：
   `meow-server/src/main/java/com/miaomiao/assistant/websocket/service/ASRService.java:28`
2. `asrManager.speechToText(...)` 调具体 provider
3. 识别结果下发 `stt` 给前端：
   `meow-server/src/main/java/com/miaomiao/assistant/websocket/service/ConversationService.java:50`
4. 然后直接复用文本链路（进入 LLM + TTS）

## 6. TTS 内部细节（复杂环节）

### 6.1 文本聚合（降低延迟 + 避免断句）

`TextAggregator.append()`：
`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/pipeline/TextAggregator.java:179`

当前策略是 `HYBRID`：

1. 首句用更激进标点（逗号等）快速触发
2. 后续句用 `SentenceDetector` 做更稳的句边界检测
3. 对拉丁标点启用 lookahead（避免把 `Mr.` `29.95` 误判为句末）

### 6.2 提交 TTS 前预处理

`TextPreProcessorPipeline.process()`：
`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/pipeline/TextPreProcessorPipeline.java:44`

顺序：

1. `MarkdownTextFilter` 先过滤 markdown/emoji 等
2. `LongTextSplitter` 再按长度与语义边界拆段

### 6.3 并发 TTS + 有序播放

入口：
`ConcurrentTTSProcessor.submitTask()`：
`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/pipeline/ConcurrentTTSProcessor.java:154`

机制：

1. 多线程并发调用 TTS API（`executeTask`）
2. 每个任务带自增 `sequence`
3. 完成结果先放 `pendingResults`
4. `tryDispatchResults()` 只按 `expectedSequence` 出队
5. 消费线程 `consumeResults()` 发送音频，保证播放顺序

### 6.4 PCM -> Opus 编码

`OpusCodec.encodePcmToOpus()`：
`meow-server/src/main/java/com/miaomiao/assistant/codec/OpusCodec.java:48`

编码参数：

1. 采样率 `24000`
2. 声道 `1`
3. 帧长 `20ms`（`480` samples）

注意点：

1. 每次调用创建独立 native codec，避免并发污染：
   `meow-server/src/main/java/com/miaomiao/assistant/codec/OpusCodec.java:32`
2. 输出为多帧串联，每帧前带 2 字节长度头

### 6.5 帧发送节奏

`sendAudioWithTiming()`：
`meow-server/src/main/java/com/miaomiao/assistant/websocket/service/pipeline/ConcurrentTTSProcessor.java:304`

行为：

1. 每帧 `audioSender.accept(frame, isLastFrame)`
2. 非最后帧 `sleep(18ms)` 近似实时播放节奏
3. 最后一帧 `finished=true`，供前端做段边界处理

## 7. 前端 Opus 播放细节

入口：
`handleMessage(type==='tts')`：
`meow-client/src/views/ChatView.vue:126`

调用：
`opusPlayer.feed(audioData, Boolean(data.finished))`：
`meow-client/src/views/ChatView.vue:173`

播放器关键机制：

1. 串行解码链：
   `feedChain` 保证多个 `feed` 顺序执行
2. 半包缓存：
   `pendingOpusBytes` 处理跨消息拆帧
3. 逐批解码：
   `decoder.decodeFrames(frames)`
4. 无缝调度：
   `nextStartTime = start + duration`
5. 段结束：
   `isLastFrame=true` 时重建 decoder，清理跨段状态

关键位置：

1. `feed()`：`meow-client/src/utils/opusPlayer.js:119`
2. `processFeed()`：`meow-client/src/utils/opusPlayer.js:131`
3. `parseOpusFrames()`：`meow-client/src/utils/opusPlayer.js:82`
4. `scheduleBuffer()`：`meow-client/src/utils/opusPlayer.js:184`

## 8. 会话状态与中断

`SessionState` 维护每个 WebSocket 会话的状态：
`meow-server/src/main/java/com/miaomiao/assistant/websocket/session/SessionState.java:20`

核心字段：

1. `audioBuffer`：接收中的音频累积缓冲
2. `conversationHistory`：上下文历史
3. `activeDisposable`：当前活跃流（用于中断）
4. `aborted`：中断标记

中断路径：

1. 新请求开始时会替换并取消上一条活跃订阅（`setActiveDisposable`）
2. 会话关闭或内部中断时调用 `abort()`，后续 `takeWhile(!aborted)` 自动停止

## 9. 性能指标与落盘

`PerformanceMetrics`：
`meow-server/src/main/java/com/miaomiao/assistant/websocket/session/PerformanceMetrics.java`

会记录：

1. 用户输入起点
2. LLM 首 token 时间
3. TTS 首帧时间

并异步保存：

1. `tts_xxx.pcm`
2. `tts_xxx.opus`

输出目录：
`tts_output/<sessionId>_<timestamp>/`

## 10. 端到端时序图（文本输入）

```text
User
  -> ChatView.sendText
  -> websocketStore.send(type=text)
  -> ConversationWebSocketHandler
  -> MessageHandlerRegistry.dispatch
  -> TextMessageHandler
  -> ConversationService.processTextInput
  -> LLMService.processLLMStream
  -> (llm_token -> 前端打字效果)
  -> tokenSink -> TTSService.processTTSStream
  -> ConcurrentTTSFrameProcessor
  -> TextAggregator + TextPreProcessorPipeline
  -> ConcurrentTTSProcessor (并发TTS、按序消费)
  -> OpusCodec.encodePcmToOpus
  -> WebSocketMessageSender.sendTTSAudio(逐帧)
  -> ChatView.handleMessage(type=tts)
  -> OpusStreamPlayer.feed
  -> OpusDecoder.decodeFrames + WebAudio schedule
  -> Speaker
```

## 11. 当前实现注意点（建议保留认知）

1. `AudioMessage.format` 已接入 ASR，支持 `audio/webm;codecs=opus` 这类 MIME 格式并在后端归一化。
2. `application.yml` 有 `tts.concurrent.enabled`，当前代码路径未基于该开关分支，主链路直接使用并发 TTS。
